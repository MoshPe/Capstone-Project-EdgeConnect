{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"class Config(dict):\n    def __init__(self):\n        self._dict = dict()\n        self._dict['PATH'] = os.path.dirname('/kaggle/working/')\n    def __getattr__(self, name):\n        if self._dict.get(name) is not None:\n            return self._dict[name]\n        if DEFAULT_CONFIG.get(name) is not None:\n            return DEFAULT_CONFIG[name]\n        return None\n\n\nDEFAULT_CONFIG = {\n    'MODE': 1,                      # 1: train, 2: test, 3: eval\n    'MODEL': 1,                     # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n    'MASK': 3,                      # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n    'EDGE': 1,                      # 1: canny, 2: external\n    'NMS': 1,                       # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n    'SEED': 10,                     # random seed\n    'GPU': [0],                     # list of gpu ids\n    'DEBUG': 0,                     # turns on debugging mode\n    'VERBOSE': 2,                   # turns on verbose mode in the output console\n\n    'LR': 0.0001,                   # learning rate\n    'D2G_LR': 0.1,                  # discriminator/generator learning rate ratio\n    'BETA1': 0.0,                   # adam optimizer beta1\n    'BETA2': 0.9,                   # adam optimizer beta2\n    'BATCH_SIZE': 8,                # input batch size for training\n    'INPUT_SIZE': 256,              # input image size for training 0 for original size\n    'SIGMA': 2,                     # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n    'MAX_ITERS': 2e6,               # maximum number of iterations to train the model\n\n    'EDGE_THRESHOLD': 0.5,          # edge detection threshold\n    'L1_LOSS_WEIGHT': 1,            # l1 loss weight\n    'FM_LOSS_WEIGHT': 10,           # feature-matching loss weight\n    'STYLE_LOSS_WEIGHT': 1,         # style loss weight\n    'CONTENT_LOSS_WEIGHT': 1,       # perceptual loss weight\n    'INPAINT_ADV_LOSS_WEIGHT': 0.01,# adversarial loss weight\n\n    'GAN_LOSS': 'hinge',            # nsgan | lsgan | hinge\n    'GAN_POOL_SIZE': 0,             # fake images pool size\n\n    'SAVE_INTERVAL': 1,          # how many iterations to wait before saving model (0: never)\n    'SAMPLE_INTERVAL': 0,        # how many iterations to wait before sampling (0: never)\n    'SAMPLE_SIZE': 12,              # number of images to sample\n    'EVAL_INTERVAL': 0,             # how many iterations to wait before model evaluation (0: never)\n    'LOG_INTERVAL': 10,             # how many iterations to wait before logging training status (0: never)\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport scipy\nimport torch\nimport random\nimport numpy as np\nimport torchvision.transforms.functional as F\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport skimage\nimport matplotlib.pyplot as plt\nfrom skimage.feature import canny\nfrom skimage.color import rgb2gray, gray2rgb\n\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, input_size, filepath, augment=True, training=True, maskType=1):\n        super(Dataset, self).__init__()\n        self.augment = augment\n        self.training = training\n        self.data = self.load_flist(filepath)\n        self.input_size = input_size\n#             self.edge_data = self.load_flist(edge_flist)\n#             self.mask_data = self.load_flist(mask_flist)\n        self.sigma = 1.5\n        self.nms = 1\n        self.mask = maskType\n\n        # in test mode, there's a one-to-one relationship between mask and image\n        # masks are loaded non random\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        try:\n            item = self.load_item(index)\n        except:\n            print('loading error: ' + self.data[index])\n            item = self.load_item(0)\n\n        return item\n\n    def load_flist(self, flist):\n        imagesPath = []\n        for filename in os.listdir(flist):\n            imagesPath.append(os.path.join(flist,filename))\n        return imagesPath\n\n    def load_item(self, index):\n        size = self.input_size\n        img =  cv2.imread(self.data[index])\n        if len(img.shape) < 3:\n            img = gray2rgb(img)\n        if size != 0:\n            img = self.resize(img, size, size)\n        img_gray = rgb2gray(img)\n        mask = self.load_mask(img, index)\n        edge = self.load_edge(img_gray, index, mask)\n        if self.augment and np.random.binomial(1, 0.5) > 0:\n            img = img[:, ::-1, ...]\n            img_gray = img_gray[:, ::-1, ...]\n            edge = edge[:, ::-1, ...]\n            mask = mask[:, ::-1, ...]\n\n        return self.to_tensor(img), self.to_tensor(img_gray), self.to_tensor(edge), self.to_tensor(mask)\n    \n    def load_edge(self, img, index, mask):\n        sigma = self.sigma\n        mask = None if self.training else (1 - mask / 255).astype(np.bool)\n\n        # canny\n        # no edge\n        if sigma == -1:\n            return np.zeros(img.shape).astype(np.float)\n\n        # random sigma\n        if sigma == 0:\n            sigma = random.randint(1, 4)\n\n        return canny(img, sigma=sigma, mask=mask).astype(np.float)\n    \n    def load_mask(self, img, index):\n        imgh, imgw = img.shape[0:2]\n        mask_type = self.mask\n\n        # external + random block\n        if mask_type == 4:\n            mask_type = 1 if np.random.binomial(1, 0.5) == 1 else 3\n\n        # external + random block + half\n        elif mask_type == 5:\n            mask_type = np.random.randint(1, 4)\n\n        # random block\n        if mask_type == 1:\n            return self.create_mask(imgw, imgh, imgw // 4, imgh // 4)\n\n        # half\n        if mask_type == 2:\n            # randomly choose right or left\n            return self.create_mask(imgw, imgh, imgw // 2, imgh, 0 if random.random() < 0.5 else imgw // 2, 0)\n\n        # external\n        if mask_type == 3:\n            mask_index = random.randint(0, len(self.mask_data) - 1)\n            mask = imread(self.mask_data[mask_index])\n            mask = self.resize(mask, imgh, imgw)\n            mask = (mask > 0).astype(np.uint8) * 255       # threshold due to interpolation\n            return mask\n\n        # test mode: load mask non random\n        if mask_type == 6:\n            mask = imread(self.mask_data[index])\n            mask = self.resize(mask, imgh, imgw, centerCrop=False)\n            mask = rgb2gray(mask)\n            mask = (mask > 0).astype(np.uint8) * 255\n            return mask\n        \n    def resize(self, img, height, width, centerCrop=True):\n        imgh, imgw = img.shape[0:2]\n        if centerCrop and imgh != imgw:\n            # center crop\n            side = np.minimum(imgh, imgw)\n            j = (imgh - side) // 2\n            i = (imgw - side) // 2\n            img = img[j:j + side, i:i + side, ...]\n\n        img = cv2.resize(img, (height, width))\n        return img  \n    \n    def to_tensor(self, img):\n        img = Image.fromarray(img)\n#         plt.imshow(img)    \n#         plt.show()\n        img_t = F.to_tensor(img).float()\n        return img_t\n    \n    def create_mask(self, width, height, mask_width, mask_height, x=None, y=None):\n        mask = np.zeros((height, width))\n        mask_x = x if x is not None else random.randint(0, width - mask_width)\n        mask_y = y if y is not None else random.randint(0, height - mask_height)\n        mask[mask_y:mask_y + mask_height, mask_x:mask_x + mask_width] = 1\n        return mask","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass BaseNetwork(nn.Module):\n    def __init__(self):\n        super(BaseNetwork, self).__init__()\n\n    def init_weights(self, init_type='normal', gain=0.02):\n        '''\n        initialize network's weights\n        init_type: normal | xavier | kaiming | orthogonal\n        https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/9451e70673400885567d08a9e97ade2524c700d0/models/networks.py#L39\n        '''\n\n        def init_func(m):\n            classname = m.__class__.__name__\n            if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n                if init_type == 'normal':\n                    nn.init.normal_(m.weight.data, 0.0, gain)\n                elif init_type == 'xavier':\n                    nn.init.xavier_normal_(m.weight.data, gain=gain)\n                elif init_type == 'kaiming':\n                    nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n                elif init_type == 'orthogonal':\n                    nn.init.orthogonal_(m.weight.data, gain=gain)\n\n                if hasattr(m, 'bias') and m.bias is not None:\n                    nn.init.constant_(m.bias.data, 0.0)\n\n            elif classname.find('BatchNorm2d') != -1:\n                nn.init.normal_(m.weight.data, 1.0, gain)\n                nn.init.constant_(m.bias.data, 0.0)\n\n        self.apply(init_func)\n\n\nclass EdgeGenerator(BaseNetwork):\n    def __init__(self, residual_blocks=8, use_spectral_norm=True, init_weights=True):\n        super(EdgeGenerator, self).__init__()\n\n        self.encoder = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            spectral_norm(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, padding=0), use_spectral_norm),\n            nn.InstanceNorm2d(64, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(128, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(256, track_running_stats=False),\n            nn.ReLU(True)\n        )\n\n        blocks = []\n        for _ in range(residual_blocks):\n            block = ResnetBlock(256, 2, use_spectral_norm=use_spectral_norm)\n            blocks.append(block)\n\n        self.middle = nn.Sequential(*blocks)\n\n        self.decoder = nn.Sequential(\n            spectral_norm(nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(128, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(64, track_running_stats=False),\n            nn.ReLU(True),\n\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(in_channels=64, out_channels=1, kernel_size=7, padding=0),\n        )\n\n        if init_weights:\n            self.init_weights()\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.middle(x)\n        x = self.decoder(x)\n        x = torch.sigmoid(x)\n        return x\n\n\nclass Discriminator(BaseNetwork):\n    def __init__(self, in_channels, use_sigmoid=True, use_spectral_norm=True, init_weights=True):\n        super(Discriminator, self).__init__()\n        self.use_sigmoid = use_sigmoid\n\n        self.conv1 = self.features = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv2 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv3 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv4 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv5 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n        )\n\n        if init_weights:\n            self.init_weights()\n\n    def forward(self, x):\n        conv1 = self.conv1(x)\n        conv2 = self.conv2(conv1)\n        conv3 = self.conv3(conv2)\n        conv4 = self.conv4(conv3)\n        conv5 = self.conv5(conv4)\n\n        outputs = conv5\n        if self.use_sigmoid:\n            outputs = torch.sigmoid(conv5)\n\n        return outputs, [conv1, conv2, conv3, conv4, conv5]\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, dilation=1, use_spectral_norm=False):\n        super(ResnetBlock, self).__init__()\n        self.conv_block = nn.Sequential(\n            nn.ReflectionPad2d(dilation),\n            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=dilation, bias=not use_spectral_norm), use_spectral_norm),\n            nn.InstanceNorm2d(dim, track_running_stats=False),\n            nn.ReLU(True),\n\n            nn.ReflectionPad2d(1),\n            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.InstanceNorm2d(dim, track_running_stats=False),\n        )\n\n    def forward(self, x):\n        out = x + self.conv_block(x)\n\n        # Remove ReLU at the end of the residual block\n        # http://torch.ch/blog/2016/02/04/resnets.html\n\n        return out\n\n\ndef spectral_norm(module, mode=True):\n    if mode:\n        return nn.utils.spectral_norm(module)\n\n    return module","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n\nclass AdversarialLoss(nn.Module):\n    r\"\"\"\n    Adversarial loss\n    https://arxiv.org/abs/1711.10337\n    \"\"\"\n\n    def __init__(self, type='nsgan', target_real_label=1.0, target_fake_label=0.0):\n        r\"\"\"\n        type = nsgan | lsgan | hinge\n        \"\"\"\n        super(AdversarialLoss, self).__init__()\n\n        self.type = type\n        self.register_buffer('real_label', torch.tensor(target_real_label))\n        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n\n        if type == 'nsgan':\n            self.criterion = nn.BCELoss()\n\n        elif type == 'lsgan':\n            self.criterion = nn.MSELoss()\n\n        elif type == 'hinge':\n            self.criterion = nn.ReLU()\n\n    def __call__(self, outputs, is_real, is_disc=None):\n        if self.type == 'hinge':\n            if is_disc:\n                if is_real:\n                    outputs = -outputs\n                return self.criterion(1 + outputs).mean()\n            else:\n                return (-outputs).mean()\n\n        else:\n            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n            loss = self.criterion(outputs, labels)\n            return loss\n\n\nclass StyleLoss(nn.Module):\n    r\"\"\"\n    Perceptual loss, VGG-based\n    https://arxiv.org/abs/1603.08155\n    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n    \"\"\"\n\n    def __init__(self):\n        super(StyleLoss, self).__init__()\n        self.add_module('vgg', VGG19())\n        self.criterion = torch.nn.L1Loss()\n\n    def compute_gram(self, x):\n        b, ch, h, w = x.size()\n        f = x.view(b, ch, w * h)\n        f_T = f.transpose(1, 2)\n        G = f.bmm(f_T) / (h * w * ch)\n\n        return G\n\n    def __call__(self, x, y):\n        # Compute features\n        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n\n        # Compute loss\n        style_loss = 0.0\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu2_2']), self.compute_gram(y_vgg['relu2_2']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu3_4']), self.compute_gram(y_vgg['relu3_4']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu4_4']), self.compute_gram(y_vgg['relu4_4']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu5_2']), self.compute_gram(y_vgg['relu5_2']))\n\n        return style_loss\n\n\n\nclass PerceptualLoss(nn.Module):\n    r\"\"\"\n    Perceptual loss, VGG-based\n    https://arxiv.org/abs/1603.08155\n    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n    \"\"\"\n\n    def __init__(self, weights=[1.0, 1.0, 1.0, 1.0, 1.0]):\n        super(PerceptualLoss, self).__init__()\n        self.add_module('vgg', VGG19())\n        self.criterion = torch.nn.L1Loss()\n        self.weights = weights\n\n    def __call__(self, x, y):\n        # Compute features\n        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n\n        content_loss = 0.0\n        content_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\n        content_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\n        content_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\n        content_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\n        content_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n\n\n        return content_loss\n\n\n\nclass VGG19(torch.nn.Module):\n    def __init__(self):\n        super(VGG19, self).__init__()\n        features = models.vgg19(pretrained=True).features\n        self.relu1_1 = torch.nn.Sequential()\n        self.relu1_2 = torch.nn.Sequential()\n\n        self.relu2_1 = torch.nn.Sequential()\n        self.relu2_2 = torch.nn.Sequential()\n\n        self.relu3_1 = torch.nn.Sequential()\n        self.relu3_2 = torch.nn.Sequential()\n        self.relu3_3 = torch.nn.Sequential()\n        self.relu3_4 = torch.nn.Sequential()\n\n        self.relu4_1 = torch.nn.Sequential()\n        self.relu4_2 = torch.nn.Sequential()\n        self.relu4_3 = torch.nn.Sequential()\n        self.relu4_4 = torch.nn.Sequential()\n\n        self.relu5_1 = torch.nn.Sequential()\n        self.relu5_2 = torch.nn.Sequential()\n        self.relu5_3 = torch.nn.Sequential()\n        self.relu5_4 = torch.nn.Sequential()\n\n        for x in range(2):\n            self.relu1_1.add_module(str(x), features[x])\n\n        for x in range(2, 4):\n            self.relu1_2.add_module(str(x), features[x])\n\n        for x in range(4, 7):\n            self.relu2_1.add_module(str(x), features[x])\n\n        for x in range(7, 9):\n            self.relu2_2.add_module(str(x), features[x])\n\n        for x in range(9, 12):\n            self.relu3_1.add_module(str(x), features[x])\n\n        for x in range(12, 14):\n            self.relu3_2.add_module(str(x), features[x])\n\n        for x in range(14, 16):\n            self.relu3_3.add_module(str(x), features[x])\n\n        for x in range(16, 18):\n            self.relu3_4.add_module(str(x), features[x])\n\n        for x in range(18, 21):\n            self.relu4_1.add_module(str(x), features[x])\n\n        for x in range(21, 23):\n            self.relu4_2.add_module(str(x), features[x])\n\n        for x in range(23, 25):\n            self.relu4_3.add_module(str(x), features[x])\n\n        for x in range(25, 27):\n            self.relu4_4.add_module(str(x), features[x])\n\n        for x in range(27, 30):\n            self.relu5_1.add_module(str(x), features[x])\n\n        for x in range(30, 32):\n            self.relu5_2.add_module(str(x), features[x])\n\n        for x in range(32, 34):\n            self.relu5_3.add_module(str(x), features[x])\n\n        for x in range(34, 36):\n            self.relu5_4.add_module(str(x), features[x])\n\n        # don't need the gradients, just want the features\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        relu1_1 = self.relu1_1(x)\n        relu1_2 = self.relu1_2(relu1_1)\n\n        relu2_1 = self.relu2_1(relu1_2)\n        relu2_2 = self.relu2_2(relu2_1)\n\n        relu3_1 = self.relu3_1(relu2_2)\n        relu3_2 = self.relu3_2(relu3_1)\n        relu3_3 = self.relu3_3(relu3_2)\n        relu3_4 = self.relu3_4(relu3_3)\n\n        relu4_1 = self.relu4_1(relu3_4)\n        relu4_2 = self.relu4_2(relu4_1)\n        relu4_3 = self.relu4_3(relu4_2)\n        relu4_4 = self.relu4_4(relu4_3)\n\n        relu5_1 = self.relu5_1(relu4_4)\n        relu5_2 = self.relu5_2(relu5_1)\n        relu5_3 = self.relu5_3(relu5_2)\n        relu5_4 = self.relu5_4(relu5_3)\n\n        out = {\n            'relu1_1': relu1_1,\n            'relu1_2': relu1_2,\n\n            'relu2_1': relu2_1,\n            'relu2_2': relu2_2,\n\n            'relu3_1': relu3_1,\n            'relu3_2': relu3_2,\n            'relu3_3': relu3_3,\n            'relu3_4': relu3_4,\n\n            'relu4_1': relu4_1,\n            'relu4_2': relu4_2,\n            'relu4_3': relu4_3,\n            'relu4_4': relu4_4,\n\n            'relu5_1': relu5_1,\n            'relu5_2': relu5_2,\n            'relu5_3': relu5_3,\n            'relu5_4': relu5_4,\n        }\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\nclass BaseModel(nn.Module):\n    def __init__(self, name, config):\n        super(BaseModel, self).__init__()\n\n        self.name = name\n        self.config = config\n        self.iteration = 0\n\n        print(config.PATH)\n        \n        self.gen_weights_path = os.path.join(config.PATH, name + '_gen.pth')\n        self.dis_weights_path = os.path.join(config.PATH, name + '_dis.pth')\n\n    def load(self):\n        print('in load', self.name)\n        if os.path.exists(self.gen_weights_path):\n            print('Loading %s generator...' % self.name)\n\n            if torch.cuda.is_available():\n                data = torch.load(self.gen_weights_path)\n            else:\n                data = torch.load(self.gen_weights_path, map_location=lambda storage, loc: storage)\n\n            self.generator.load_state_dict(data['generator'])\n            self.iteration = data['iteration']\n\n        # load discriminator only when training\n        if self.config.MODE == 1 and os.path.exists(self.dis_weights_path):\n            print('Loading %s discriminator...' % self.name)\n\n            if torch.cuda.is_available():\n                data = torch.load(self.dis_weights_path)\n            else:\n                data = torch.load(self.dis_weights_path, map_location=lambda storage, loc: storage)\n\n            self.discriminator.load_state_dict(data['discriminator'])\n\n    def save(self):\n        print('\\nsaving %s...\\n' % self.name)\n        torch.save({\n            'iteration': self.iteration,\n            'generator': self.generator.state_dict()\n        }, self.gen_weights_path)\n\n        torch.save({\n            'discriminator': self.discriminator.state_dict()\n        }, self.dis_weights_path)\n\n\nclass EdgeModel(BaseModel):\n    def __init__(self, config):\n        super(EdgeModel, self).__init__('EdgeModel', config)\n\n        # generator input: [grayscale(1) + edge(1) + mask(1)]\n        # discriminator input: (grayscale(1) + edge(1))\n        generator = EdgeGenerator(use_spectral_norm=True)\n        discriminator = Discriminator(in_channels=2, use_sigmoid=config.GAN_LOSS != 'hinge')\n        if len(config.GPU) > 1:\n            generator = nn.DataParallel(generator, device_ids=[0, 1])\n            discriminator = nn.DataParallel(discriminator, config.GPU)\n        l1_loss = nn.L1Loss()\n        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n\n        self.add_module('generator', generator)\n        self.add_module('discriminator', discriminator)\n\n        self.add_module('l1_loss', l1_loss)\n        self.add_module('adversarial_loss', adversarial_loss)\n\n        self.gen_optimizer = optim.Adam(\n            params=generator.parameters(),\n            lr=float(config.LR),\n            betas=(config.BETA1, config.BETA2)\n        )\n\n        self.dis_optimizer = optim.Adam(\n            params=discriminator.parameters(),\n            lr=float(config.LR) * float(config.D2G_LR),\n            betas=(config.BETA1, config.BETA2)\n        )\n\n    def process(self, images, edges, masks):\n        self.iteration += 1\n\n\n        # zero optimizers\n        self.gen_optimizer.zero_grad()\n        self.dis_optimizer.zero_grad()\n\n\n        # process outputs\n        outputs = self(images, edges, masks)\n        gen_loss = 0\n        dis_loss = 0\n\n\n        # discriminator loss\n        dis_input_real = torch.cat((images, edges), dim=1)\n        dis_input_fake = torch.cat((images, outputs.detach()), dim=1)\n        dis_real, dis_real_feat = self.discriminator(dis_input_real)        # in: (grayscale(1) + edge(1))\n        dis_fake, dis_fake_feat = self.discriminator(dis_input_fake)        # in: (grayscale(1) + edge(1))\n        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n        dis_loss += (dis_real_loss.clone() + dis_fake_loss.clone()) / 2\n\n\n        # generator adversarial loss\n        gen_input_fake = torch.cat((images, outputs), dim=1)\n        gen_fake, gen_fake_feat = self.discriminator(gen_input_fake)        # in: (grayscale(1) + edge(1))\n        gen_gan_loss = self.adversarial_loss(gen_fake, True, False)\n        gen_loss += gen_gan_loss.clone()\n\n\n        # generator feature matching loss\n        gen_fm_loss = 0\n        for i in range(len(dis_real_feat)):\n            gen_fm_loss += self.l1_loss(gen_fake_feat[i], dis_real_feat[i].detach())\n        gen_fm_loss = gen_fm_loss * self.config.FM_LOSS_WEIGHT\n        gen_loss += gen_fm_loss\n\n\n        # create logs\n        logs = [\n            (\"l_d1\", dis_loss.item()),\n            (\"l_g1\", gen_gan_loss.item()),\n            (\"l_fm\", gen_fm_loss.item()),\n        ]\n\n        return outputs, gen_loss, dis_loss, logs\n\n    def forward(self, images, edges, masks):\n        edges_masked = (edges * (1 - masks))\n        images_masked = (images * (1 - masks)) + masks\n        inputs = torch.cat((images_masked, edges_masked, masks), dim=1)\n        outputs = self.generator(inputs)                                    # in: [grayscale(1) + edge(1) + mask(1)]\n        return outputs\n\n    def backward(self, gen_loss=None, dis_loss=None):\n        if dis_loss is not None:\n            dis_loss.backward()\n\n        if gen_loss is not None:\n            gen_loss.backward()\n        self.gen_optimizer.step()\n        self.dis_optimizer.step()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass EdgeAccuracy(nn.Module):\n    \"\"\"\n    Measures the accuracy of the edge map\n    \"\"\"\n    def __init__(self, threshold=0.5):\n        super(EdgeAccuracy, self).__init__()\n        self.threshold = threshold\n\n    def __call__(self, inputs, outputs):\n        labels = (inputs > self.threshold)\n        outputs = (outputs > self.threshold)\n\n        relevant = torch.sum(labels.float())\n        selected = torch.sum(outputs.float())\n\n        if relevant == 0 and selected == 0:\n            return torch.tensor(1), torch.tensor(1)\n\n        true_positive = ((outputs == labels) * labels).float()\n        recall = torch.sum(true_positive) / (relevant + 1e-8)\n        precision = torch.sum(true_positive) / (selected + 1e-8)\n\n        return precision, recall\n\n\nclass PSNR(nn.Module):\n    def __init__(self, max_val):\n        super(PSNR, self).__init__()\n\n        base10 = torch.log(torch.tensor(10.0))\n        max_val = torch.tensor(max_val).float()\n\n        self.register_buffer('base10', base10)\n        self.register_buffer('max_val', 20 * torch.log(max_val) / base10)\n\n    def __call__(self, a, b):\n        mse = torch.mean((a.float() - b.float()) ** 2)\n\n        if mse == 0:\n            return torch.tensor(0)\n\n        return self.max_val - 10 * torch.log(mse) / self.base10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nclass Progbar(object):\n    \"\"\"Displays a progress bar.\n    Arguments:\n        target: Total number of steps expected, None if unknown.\n        width: Progress bar width on screen.\n        verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n        stateful_metrics: Iterable of string names of metrics that\n            should *not* be averaged over time. Metrics in this list\n            will be displayed as-is. All others will be averaged\n            by the progbar before display.\n        interval: Minimum visual progress update interval (in seconds).\n    \"\"\"\n\n    def __init__(self, target, width=25, verbose=1, interval=0.05,\n                 stateful_metrics=None):\n        self.target = target\n        self.width = width\n        self.verbose = verbose\n        self.interval = interval\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()\n\n        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n                                  sys.stdout.isatty()) or\n                                 'ipykernel' in sys.modules or\n                                 'posix' in sys.modules)\n        self._total_width = 0\n        self._seen_so_far = 0\n        # We use a dict + list to avoid garbage collection\n        # issues found in OrderedDict\n        self._values = {}\n        self._values_order = []\n        self._start = time.time()\n        self._last_update = 0\n\n    def update(self, current, values=None):\n        \"\"\"Updates the progress bar.\n        Arguments:\n            current: Index of current step.\n            values: List of tuples:\n                `(name, value_for_last_step)`.\n                If `name` is in `stateful_metrics`,\n                `value_for_last_step` will be displayed as-is.\n                Else, an average of the metric over time will be displayed.\n        \"\"\"\n        values = values or []\n        for k, v in values:\n            if k not in self._values_order:\n                self._values_order.append(k)\n            if k not in self.stateful_metrics:\n                if k not in self._values:\n                    self._values[k] = [v * (current - self._seen_so_far),\n                                       current - self._seen_so_far]\n                else:\n                    self._values[k][0] += v * (current - self._seen_so_far)\n                    self._values[k][1] += (current - self._seen_so_far)\n            else:\n                self._values[k] = v\n        self._seen_so_far = current\n\n        now = time.time()\n        info = ' - %.0fs' % (now - self._start)\n        if self.verbose == 1:\n            if (now - self._last_update < self.interval and\n                    self.target is not None and current < self.target):\n                return\n\n            prev_total_width = self._total_width\n            if self._dynamic_display:\n                sys.stdout.write('\\b' * prev_total_width)\n                sys.stdout.write('\\r')\n            else:\n                sys.stdout.write('\\n')\n\n            if self.target is not None:\n                numdigits = int(np.floor(np.log10(self.target))) + 1\n                barstr = '%%%dd/%d [' % (numdigits, self.target)\n                bar = barstr % current\n                prog = float(current) / self.target\n                prog_width = int(self.width * prog)\n                if prog_width > 0:\n                    bar += ('=' * (prog_width - 1))\n                    if current < self.target:\n                        bar += '>'\n                    else:\n                        bar += '='\n                bar += ('.' * (self.width - prog_width))\n                bar += ']'\n            else:\n                bar = '%7d/Unknown' % current\n\n            self._total_width = len(bar)\n#             sys.stdout.write(bar)\n            print(bar)\n\n            if current:\n                time_per_unit = (now - self._start) / current\n            else:\n                time_per_unit = 0\n            if self.target is not None and current < self.target:\n                eta = time_per_unit * (self.target - current)\n                if eta > 3600:\n                    eta_format = '%d:%02d:%02d' % (eta // 3600,\n                                                   (eta % 3600) // 60,\n                                                   eta % 60)\n                elif eta > 60:\n                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n                else:\n                    eta_format = '%ds' % eta\n\n                info = ' - ETA: %s' % eta_format\n            else:\n                if time_per_unit >= 1:\n                    info += ' %.0fs/step' % time_per_unit\n                elif time_per_unit >= 1e-3:\n                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n                else:\n                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n\n            for k in self._values_order:\n                info += ' - %s:' % k\n                if isinstance(self._values[k], list):\n                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n                    if abs(avg) > 1e-3:\n                        info += ' %.4f' % avg\n                    else:\n                        info += ' %.4e' % avg\n                else:\n                    info += ' %s' % self._values[k]\n\n            self._total_width += len(info)\n            if prev_total_width > self._total_width:\n                info += (' ' * (prev_total_width - self._total_width))\n\n            if self.target is not None and current >= self.target:\n                info += '\\n'\n\n#             sys.stdout.write(info)\n            print(info)\n\n        elif self.verbose == 2:\n            if self.target is None or current >= self.target:\n                for k in self._values_order:\n                    info += ' - %s:' % k\n                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n                    if avg > 1e-3:\n                        info += ' %.4f' % avg\n                    else:\n                        info += ' %.4e' % avg\n                info += '\\n'\n\n                sys.stdout.write(info)\n                print(info)\n        self._last_update = now\n\n    def add(self, n, values=None):\n        self.update(self._seen_so_far + n, values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nimport tensorflow as tf\n# from .dataset import Dataset\n# from .models import EdgeModel, InpaintingModel\n# from .utils import Progbar, create_dir, stitch_images, imsave\n# from .metrics import PSNR, EdgeAccuracy\n\n\nclass EdgeConnect():\n    \n    def cuda(self, *args):\n        return (item.to(self.config.DEVICE) for item in args)\n    \n    def load(self):\n        self.edge_model.load()\n\n    def save(self):\n        self.edge_model.save()\n        \n    def log(self, logs):\n        with open(self.log_file, 'a') as f:\n            f.write('%s\\n' % ' '.join([str(item[1]) for item in logs]))\n    \n    def __init__(self, config):\n        self.config = config\n        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in config.GPU)\n        if torch.cuda.is_available():\n            config.DEVICE = torch.device(\"cuda\")\n            torch.backends.cudnn.benchmark = True   # cudnn auto-tuner\n        else:\n            config.DEVICE = torch.device(\"cpu\")\n        print(torch.cuda.is_available())\n        self.edge_model = EdgeModel(config).to(config.DEVICE)\n        self.edgeacc = EdgeAccuracy(config.EDGE_THRESHOLD).to(config.DEVICE)\n        self.psnr = PSNR(255.0).to(config.DEVICE)\n#         self.inpaint_model = InpaintingModel(config).to(config.DEVICE)\n        self.train_dataset = Dataset(256, '/kaggle/input/train-test-set/val_256', augment=True, training=True)\n        \n        \n        \n        # Train\n        epoch = 0\n        keep_training = True\n        max_iteration = int(float((self.config.MAX_ITERS)))\n        total = len(self.train_dataset)\n        train_loader = DataLoader(\n            dataset=self.train_dataset,\n            batch_size=self.config.BATCH_SIZE,\n            num_workers=4,\n            drop_last=True,\n            shuffle=True\n        )\n        model_name = 'edge generator'\n        self.log_file = os.path.join(config.PATH, 'log_' + model_name + '.dat')\n        self.load()\n        \n        while(keep_training):\n            epoch += 1\n            print('\\n\\nTraining epoch: %d' % epoch)\n\n            progbar = Progbar(total, width=20, verbose=1, stateful_metrics=['epoch', 'iter'])\n            for items in train_loader:\n\n                self.edge_model.train()\n                images, images_gray, edges, masks = self.cuda(*items)\n                outputs, gen_loss, dis_loss, logs = self.edge_model.process(images_gray, edges, masks)\n\n                # metrics\n                precision, recall = self.edgeacc(edges * masks, outputs * masks)\n                logs.append(('precision', precision.item()))\n                logs.append(('recall', recall.item()))\n\n                # backward\n                self.edge_model.backward(gen_loss, dis_loss)\n                iteration = self.edge_model.iteration\n\n                if iteration >= max_iteration:\n                    keep_training = False\n                    break\n\n                logs = [\n                    (\"epoch\", epoch),\n                    (\"iter\", iteration),\n                ] + logs\n\n                progbar.add(len(images), values=logs if self.config.VERBOSE else [x for x in logs if not x[0].startswith('l_')])\n\n                # log model at checkpoints\n                if self.config.LOG_INTERVAL and iteration % self.config.LOG_INTERVAL == 0:\n                    self.log(logs)\n\n                # sample model at checkpoints\n                if self.config.SAMPLE_INTERVAL and iteration % self.config.SAMPLE_INTERVAL == 0:\n                    self.sample()\n\n                # evaluate model at checkpoints\n                if self.config.EVAL_INTERVAL and iteration % self.config.EVAL_INTERVAL == 0:\n                    print('\\nstart eval...\\n')\n                    self.eval()\n\n                # save model at checkpoints\n                if self.config.SAVE_INTERVAL and iteration % self.config.SAVE_INTERVAL == 0:\n                    self.save()\n\n            print('\\nEnd training....')\n\n\n    #             images = edges[0,...]\n    #             images = images[0,...]\n    #             print(tf.shape(images))\n    #             arr_ = np.squeeze(images) # you can give axis attribute if you wanna squeeze in specific dimension\n    #             plt.imshow(arr_, cmap=\"gray\")\n    #             plt.show()\n\nconfig = Config()            \nedgeConnect = EdgeConnect(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}