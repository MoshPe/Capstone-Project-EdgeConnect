{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ntorch.autograd.set_detect_anomaly(True)","metadata":{"execution":{"iopub.status.busy":"2023-03-23T16:16:23.878349Z","iopub.execute_input":"2023-03-23T16:16:23.878797Z","iopub.status.idle":"2023-03-23T16:16:23.887475Z","shell.execute_reply.started":"2023-03-23T16:16:23.878756Z","shell.execute_reply":"2023-03-23T16:16:23.886311Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f1b74200390>"},"metadata":{}}]},{"cell_type":"code","source":"class Config(dict):\n    def __init__(self):\n        self._dict = dict()\n        self._dict['PATH'] = os.path.dirname('/kaggle/working')\n    def __getattr__(self, name):\n        if self._dict.get(name) is not None:\n            return self._dict[name]\n        if DEFAULT_CONFIG.get(name) is not None:\n            return DEFAULT_CONFIG[name]\n        return None\n\n\nDEFAULT_CONFIG = {\n    'MODE': 1,                      # 1: train, 2: test, 3: eval\n    'MODEL': 1,                     # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n    'MASK': 3,                      # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n    'EDGE': 1,                      # 1: canny, 2: external\n    'NMS': 1,                       # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n    'SEED': 10,                     # random seed\n    'GPU': [0],                     # list of gpu ids\n    'DEBUG': 0,                     # turns on debugging mode\n    'VERBOSE': 0,                   # turns on verbose mode in the output console\n\n    'LR': 0.0001,                   # learning rate\n    'D2G_LR': 0.1,                  # discriminator/generator learning rate ratio\n    'BETA1': 0.0,                   # adam optimizer beta1\n    'BETA2': 0.9,                   # adam optimizer beta2\n    'BATCH_SIZE': 8,                # input batch size for training\n    'INPUT_SIZE': 256,              # input image size for training 0 for original size\n    'SIGMA': 2,                     # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n    'MAX_ITERS': 2e6,               # maximum number of iterations to train the model\n\n    'EDGE_THRESHOLD': 0.5,          # edge detection threshold\n    'L1_LOSS_WEIGHT': 1,            # l1 loss weight\n    'FM_LOSS_WEIGHT': 10,           # feature-matching loss weight\n    'STYLE_LOSS_WEIGHT': 1,         # style loss weight\n    'CONTENT_LOSS_WEIGHT': 1,       # perceptual loss weight\n    'INPAINT_ADV_LOSS_WEIGHT': 0.01,# adversarial loss weight\n\n    'GAN_LOSS': 'hinge',            # nsgan | lsgan | hinge\n    'GAN_POOL_SIZE': 0,             # fake images pool size\n\n    'SAVE_INTERVAL': 1000,          # how many iterations to wait before saving model (0: never)\n    'SAMPLE_INTERVAL': 1000,        # how many iterations to wait before sampling (0: never)\n    'SAMPLE_SIZE': 12,              # number of images to sample\n    'EVAL_INTERVAL': 0,             # how many iterations to wait before model evaluation (0: never)\n    'LOG_INTERVAL': 10,             # how many iterations to wait before logging training status (0: never)\n}","metadata":{"execution":{"iopub.status.busy":"2023-03-23T16:16:23.889798Z","iopub.execute_input":"2023-03-23T16:16:23.890509Z","iopub.status.idle":"2023-03-23T16:16:23.901743Z","shell.execute_reply.started":"2023-03-23T16:16:23.890474Z","shell.execute_reply":"2023-03-23T16:16:23.900869Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport scipy\nimport torch\nimport random\nimport numpy as np\nimport torchvision.transforms.functional as F\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport skimage\nimport matplotlib.pyplot as plt\nfrom skimage.feature import canny\nfrom skimage.color import rgb2gray, gray2rgb\n\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, input_size, filepath, augment=True, training=True, maskType=1):\n        super(Dataset, self).__init__()\n        self.augment = augment\n        self.training = training\n        self.data = self.load_flist(filepath)\n        self.input_size = input_size\n#             self.edge_data = self.load_flist(edge_flist)\n#             self.mask_data = self.load_flist(mask_flist)\n        self.sigma = 1.5\n        self.nms = 1\n        self.mask = maskType\n\n        # in test mode, there's a one-to-one relationship between mask and image\n        # masks are loaded non random\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        try:\n            item = self.load_item(index)\n        except:\n            print('loading error: ' + self.data[index])\n            item = self.load_item(0)\n\n        return item\n\n    def load_flist(self, flist):\n        imagesPath = []\n        for filename in os.listdir(flist):\n            imagesPath.append(os.path.join(flist,filename))\n        return imagesPath\n\n    def load_item(self, index):\n        size = self.input_size\n        img =  cv2.imread(self.data[index])\n        if len(img.shape) < 3:\n            img = gray2rgb(img)\n        if size != 0:\n            img = self.resize(img, size, size)\n        img_gray = rgb2gray(img)\n        mask = self.load_mask(img, index)\n        edge = self.load_edge(img_gray, index, mask)\n        if self.augment and np.random.binomial(1, 0.5) > 0:\n            img = img[:, ::-1, ...]\n            img_gray = img_gray[:, ::-1, ...]\n            edge = edge[:, ::-1, ...]\n            mask = mask[:, ::-1, ...]\n\n        return self.to_tensor(img), self.to_tensor(img_gray), self.to_tensor(edge), self.to_tensor(mask)\n    \n    def load_edge(self, img, index, mask):\n        sigma = self.sigma\n        mask = None if self.training else (1 - mask / 255).astype(np.bool)\n\n        # canny\n        # no edge\n        if sigma == -1:\n            return np.zeros(img.shape).astype(np.float)\n\n        # random sigma\n        if sigma == 0:\n            sigma = random.randint(1, 4)\n\n        return canny(img, sigma=sigma, mask=mask).astype(np.float)\n    \n    def load_mask(self, img, index):\n        imgh, imgw = img.shape[0:2]\n        mask_type = self.mask\n\n        # external + random block\n        if mask_type == 4:\n            mask_type = 1 if np.random.binomial(1, 0.5) == 1 else 3\n\n        # external + random block + half\n        elif mask_type == 5:\n            mask_type = np.random.randint(1, 4)\n\n        # random block\n        if mask_type == 1:\n            return self.create_mask(imgw, imgh, imgw // 4, imgh // 4)\n\n        # half\n        if mask_type == 2:\n            # randomly choose right or left\n            return self.create_mask(imgw, imgh, imgw // 2, imgh, 0 if random.random() < 0.5 else imgw // 2, 0)\n\n        # external\n        if mask_type == 3:\n            mask_index = random.randint(0, len(self.mask_data) - 1)\n            mask = imread(self.mask_data[mask_index])\n            mask = self.resize(mask, imgh, imgw)\n            mask = (mask > 0).astype(np.uint8) * 255       # threshold due to interpolation\n            return mask\n\n        # test mode: load mask non random\n        if mask_type == 6:\n            mask = imread(self.mask_data[index])\n            mask = self.resize(mask, imgh, imgw, centerCrop=False)\n            mask = rgb2gray(mask)\n            mask = (mask > 0).astype(np.uint8) * 255\n            return mask\n        \n    def resize(self, img, height, width, centerCrop=True):\n        imgh, imgw = img.shape[0:2]\n        if centerCrop and imgh != imgw:\n            # center crop\n            side = np.minimum(imgh, imgw)\n            j = (imgh - side) // 2\n            i = (imgw - side) // 2\n            img = img[j:j + side, i:i + side, ...]\n\n        img = cv2.resize(img, (height, width))\n        return img  \n    \n    def to_tensor(self, img):\n        img = Image.fromarray(img)\n#         plt.imshow(img)    \n#         plt.show()\n        img_t = F.to_tensor(img).float()\n        return img_t\n    \n    def create_mask(self, width, height, mask_width, mask_height, x=None, y=None):\n        mask = np.zeros((height, width))\n        mask_x = x if x is not None else random.randint(0, width - mask_width)\n        mask_y = y if y is not None else random.randint(0, height - mask_height)\n        mask[mask_y:mask_y + mask_height, mask_x:mask_x + mask_width] = 1\n        return mask","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-23T16:16:23.910499Z","iopub.execute_input":"2023-03-23T16:16:23.911150Z","iopub.status.idle":"2023-03-23T16:16:23.939331Z","shell.execute_reply.started":"2023-03-23T16:16:23.911087Z","shell.execute_reply":"2023-03-23T16:16:23.938345Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass BaseNetwork(nn.Module):\n    def __init__(self):\n        super(BaseNetwork, self).__init__()\n\n    def init_weights(self, init_type='normal', gain=0.02):\n        '''\n        initialize network's weights\n        init_type: normal | xavier | kaiming | orthogonal\n        https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/9451e70673400885567d08a9e97ade2524c700d0/models/networks.py#L39\n        '''\n\n        def init_func(m):\n            classname = m.__class__.__name__\n            if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n                if init_type == 'normal':\n                    nn.init.normal_(m.weight.data, 0.0, gain)\n                elif init_type == 'xavier':\n                    nn.init.xavier_normal_(m.weight.data, gain=gain)\n                elif init_type == 'kaiming':\n                    nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n                elif init_type == 'orthogonal':\n                    nn.init.orthogonal_(m.weight.data, gain=gain)\n\n                if hasattr(m, 'bias') and m.bias is not None:\n                    nn.init.constant_(m.bias.data, 0.0)\n\n            elif classname.find('BatchNorm2d') != -1:\n                nn.init.normal_(m.weight.data, 1.0, gain)\n                nn.init.constant_(m.bias.data, 0.0)\n\n        self.apply(init_func)\n\n\nclass EdgeGenerator(BaseNetwork):\n    def __init__(self, residual_blocks=8, use_spectral_norm=True, init_weights=True):\n        super(EdgeGenerator, self).__init__()\n\n        self.encoder = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            spectral_norm(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, padding=0), use_spectral_norm),\n            nn.InstanceNorm2d(64, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(128, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(256, track_running_stats=False),\n            nn.ReLU(True)\n        )\n\n        blocks = []\n        for _ in range(residual_blocks):\n            block = ResnetBlock(256, 2, use_spectral_norm=use_spectral_norm)\n            blocks.append(block)\n\n        self.middle = nn.Sequential(*blocks)\n\n        self.decoder = nn.Sequential(\n            spectral_norm(nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(128, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(64, track_running_stats=False),\n            nn.ReLU(True),\n\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(in_channels=64, out_channels=1, kernel_size=7, padding=0),\n        )\n\n        if init_weights:\n            self.init_weights()\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.middle(x)\n        x = self.decoder(x)\n        x = torch.sigmoid(x)\n        return x\n\n\nclass Discriminator(BaseNetwork):\n    def __init__(self, in_channels, use_sigmoid=True, use_spectral_norm=True, init_weights=True):\n        super(Discriminator, self).__init__()\n        self.use_sigmoid = use_sigmoid\n\n        self.conv1 = self.features = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv2 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv3 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv4 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv5 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n        )\n\n        if init_weights:\n            self.init_weights()\n\n    def forward(self, x):\n        conv1 = self.conv1(x)\n        conv2 = self.conv2(conv1)\n        conv3 = self.conv3(conv2)\n        conv4 = self.conv4(conv3)\n        conv5 = self.conv5(conv4)\n\n        outputs = conv5\n        if self.use_sigmoid:\n            outputs = torch.sigmoid(conv5)\n\n        return outputs, [conv1, conv2, conv3, conv4, conv5]\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, dilation=1, use_spectral_norm=False):\n        super(ResnetBlock, self).__init__()\n        self.conv_block = nn.Sequential(\n            nn.ReflectionPad2d(dilation),\n            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=dilation, bias=not use_spectral_norm), use_spectral_norm),\n            nn.InstanceNorm2d(dim, track_running_stats=False),\n            nn.ReLU(True),\n\n            nn.ReflectionPad2d(1),\n            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.InstanceNorm2d(dim, track_running_stats=False),\n        )\n\n    def forward(self, x):\n        out = x + self.conv_block(x)\n\n        # Remove ReLU at the end of the residual block\n        # http://torch.ch/blog/2016/02/04/resnets.html\n\n        return out\n\n\ndef spectral_norm(module, mode=True):\n    if mode:\n        return nn.utils.spectral_norm(module)\n\n    return module","metadata":{"execution":{"iopub.status.busy":"2023-03-23T16:16:24.023708Z","iopub.execute_input":"2023-03-23T16:16:24.024162Z","iopub.status.idle":"2023-03-23T16:16:24.060286Z","shell.execute_reply.started":"2023-03-23T16:16:24.024090Z","shell.execute_reply":"2023-03-23T16:16:24.059174Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n\nclass AdversarialLoss(nn.Module):\n    r\"\"\"\n    Adversarial loss\n    https://arxiv.org/abs/1711.10337\n    \"\"\"\n\n    def __init__(self, type='nsgan', target_real_label=1.0, target_fake_label=0.0):\n        r\"\"\"\n        type = nsgan | lsgan | hinge\n        \"\"\"\n        super(AdversarialLoss, self).__init__()\n\n        self.type = type\n        self.register_buffer('real_label', torch.tensor(target_real_label))\n        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n\n        if type == 'nsgan':\n            self.criterion = nn.BCELoss()\n\n        elif type == 'lsgan':\n            self.criterion = nn.MSELoss()\n\n        elif type == 'hinge':\n            self.criterion = nn.ReLU()\n\n    def __call__(self, outputs, is_real, is_disc=None):\n        if self.type == 'hinge':\n            if is_disc:\n                if is_real:\n                    outputs = -outputs\n                return self.criterion(1 + outputs).mean()\n            else:\n                return (-outputs).mean()\n\n        else:\n            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n            loss = self.criterion(outputs, labels)\n            return loss\n\n\nclass StyleLoss(nn.Module):\n    r\"\"\"\n    Perceptual loss, VGG-based\n    https://arxiv.org/abs/1603.08155\n    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n    \"\"\"\n\n    def __init__(self):\n        super(StyleLoss, self).__init__()\n        self.add_module('vgg', VGG19())\n        self.criterion = torch.nn.L1Loss()\n\n    def compute_gram(self, x):\n        b, ch, h, w = x.size()\n        f = x.view(b, ch, w * h)\n        f_T = f.transpose(1, 2)\n        G = f.bmm(f_T) / (h * w * ch)\n\n        return G\n\n    def __call__(self, x, y):\n        # Compute features\n        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n\n        # Compute loss\n        style_loss = 0.0\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu2_2']), self.compute_gram(y_vgg['relu2_2']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu3_4']), self.compute_gram(y_vgg['relu3_4']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu4_4']), self.compute_gram(y_vgg['relu4_4']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu5_2']), self.compute_gram(y_vgg['relu5_2']))\n\n        return style_loss\n\n\n\nclass PerceptualLoss(nn.Module):\n    r\"\"\"\n    Perceptual loss, VGG-based\n    https://arxiv.org/abs/1603.08155\n    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n    \"\"\"\n\n    def __init__(self, weights=[1.0, 1.0, 1.0, 1.0, 1.0]):\n        super(PerceptualLoss, self).__init__()\n        self.add_module('vgg', VGG19())\n        self.criterion = torch.nn.L1Loss()\n        self.weights = weights\n\n    def __call__(self, x, y):\n        # Compute features\n        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n\n        content_loss = 0.0\n        content_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\n        content_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\n        content_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\n        content_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\n        content_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n\n\n        return content_loss\n\n\n\nclass VGG19(torch.nn.Module):\n    def __init__(self):\n        super(VGG19, self).__init__()\n        features = models.vgg19(pretrained=True).features\n        self.relu1_1 = torch.nn.Sequential()\n        self.relu1_2 = torch.nn.Sequential()\n\n        self.relu2_1 = torch.nn.Sequential()\n        self.relu2_2 = torch.nn.Sequential()\n\n        self.relu3_1 = torch.nn.Sequential()\n        self.relu3_2 = torch.nn.Sequential()\n        self.relu3_3 = torch.nn.Sequential()\n        self.relu3_4 = torch.nn.Sequential()\n\n        self.relu4_1 = torch.nn.Sequential()\n        self.relu4_2 = torch.nn.Sequential()\n        self.relu4_3 = torch.nn.Sequential()\n        self.relu4_4 = torch.nn.Sequential()\n\n        self.relu5_1 = torch.nn.Sequential()\n        self.relu5_2 = torch.nn.Sequential()\n        self.relu5_3 = torch.nn.Sequential()\n        self.relu5_4 = torch.nn.Sequential()\n\n        for x in range(2):\n            self.relu1_1.add_module(str(x), features[x])\n\n        for x in range(2, 4):\n            self.relu1_2.add_module(str(x), features[x])\n\n        for x in range(4, 7):\n            self.relu2_1.add_module(str(x), features[x])\n\n        for x in range(7, 9):\n            self.relu2_2.add_module(str(x), features[x])\n\n        for x in range(9, 12):\n            self.relu3_1.add_module(str(x), features[x])\n\n        for x in range(12, 14):\n            self.relu3_2.add_module(str(x), features[x])\n\n        for x in range(14, 16):\n            self.relu3_3.add_module(str(x), features[x])\n\n        for x in range(16, 18):\n            self.relu3_4.add_module(str(x), features[x])\n\n        for x in range(18, 21):\n            self.relu4_1.add_module(str(x), features[x])\n\n        for x in range(21, 23):\n            self.relu4_2.add_module(str(x), features[x])\n\n        for x in range(23, 25):\n            self.relu4_3.add_module(str(x), features[x])\n\n        for x in range(25, 27):\n            self.relu4_4.add_module(str(x), features[x])\n\n        for x in range(27, 30):\n            self.relu5_1.add_module(str(x), features[x])\n\n        for x in range(30, 32):\n            self.relu5_2.add_module(str(x), features[x])\n\n        for x in range(32, 34):\n            self.relu5_3.add_module(str(x), features[x])\n\n        for x in range(34, 36):\n            self.relu5_4.add_module(str(x), features[x])\n\n        # don't need the gradients, just want the features\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        relu1_1 = self.relu1_1(x)\n        relu1_2 = self.relu1_2(relu1_1)\n\n        relu2_1 = self.relu2_1(relu1_2)\n        relu2_2 = self.relu2_2(relu2_1)\n\n        relu3_1 = self.relu3_1(relu2_2)\n        relu3_2 = self.relu3_2(relu3_1)\n        relu3_3 = self.relu3_3(relu3_2)\n        relu3_4 = self.relu3_4(relu3_3)\n\n        relu4_1 = self.relu4_1(relu3_4)\n        relu4_2 = self.relu4_2(relu4_1)\n        relu4_3 = self.relu4_3(relu4_2)\n        relu4_4 = self.relu4_4(relu4_3)\n\n        relu5_1 = self.relu5_1(relu4_4)\n        relu5_2 = self.relu5_2(relu5_1)\n        relu5_3 = self.relu5_3(relu5_2)\n        relu5_4 = self.relu5_4(relu5_3)\n\n        out = {\n            'relu1_1': relu1_1,\n            'relu1_2': relu1_2,\n\n            'relu2_1': relu2_1,\n            'relu2_2': relu2_2,\n\n            'relu3_1': relu3_1,\n            'relu3_2': relu3_2,\n            'relu3_3': relu3_3,\n            'relu3_4': relu3_4,\n\n            'relu4_1': relu4_1,\n            'relu4_2': relu4_2,\n            'relu4_3': relu4_3,\n            'relu4_4': relu4_4,\n\n            'relu5_1': relu5_1,\n            'relu5_2': relu5_2,\n            'relu5_3': relu5_3,\n            'relu5_4': relu5_4,\n        }\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-03-23T16:16:24.062090Z","iopub.execute_input":"2023-03-23T16:16:24.062466Z","iopub.status.idle":"2023-03-23T16:16:24.102730Z","shell.execute_reply.started":"2023-03-23T16:16:24.062433Z","shell.execute_reply":"2023-03-23T16:16:24.101549Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\nclass BaseModel(nn.Module):\n    def __init__(self, name, config):\n        super(BaseModel, self).__init__()\n\n        self.name = name\n        self.config = config\n        self.iteration = 0\n\n        print(config.PATH)\n        \n        self.gen_weights_path = os.path.join(config.PATH, name + '_gen.pth')\n        self.dis_weights_path = os.path.join(config.PATH, name + '_dis.pth')\n\n    def load(self):\n        if os.path.exists(self.gen_weights_path):\n            print('Loading %s generator...' % self.name)\n\n            if torch.cuda.is_available():\n                data = torch.load(self.gen_weights_path)\n            else:\n                data = torch.load(self.gen_weights_path, map_location=lambda storage, loc: storage)\n\n            self.generator.load_state_dict(data['generator'])\n            self.iteration = data['iteration']\n\n        # load discriminator only when training\n        if self.config.MODE == 1 and os.path.exists(self.dis_weights_path):\n            print('Loading %s discriminator...' % self.name)\n\n            if torch.cuda.is_available():\n                data = torch.load(self.dis_weights_path)\n            else:\n                data = torch.load(self.dis_weights_path, map_location=lambda storage, loc: storage)\n\n            self.discriminator.load_state_dict(data['discriminator'])\n\n    def save(self):\n        print('\\nsaving %s...\\n' % self.name)\n        torch.save({\n            'iteration': self.iteration,\n            'generator': self.generator.state_dict()\n        }, self.gen_weights_path)\n\n        torch.save({\n            'discriminator': self.discriminator.state_dict()\n        }, self.dis_weights_path)\n\n\nclass EdgeModel(BaseModel):\n    def __init__(self, config):\n        super(EdgeModel, self).__init__('EdgeModel', config)\n\n        # generator input: [grayscale(1) + edge(1) + mask(1)]\n        # discriminator input: (grayscale(1) + edge(1))\n        generator = EdgeGenerator(use_spectral_norm=True)\n        discriminator = Discriminator(in_channels=2, use_sigmoid=config.GAN_LOSS != 'hinge')\n        if len(config.GPU) > 1:\n            generator = nn.DataParallel(generator, device_ids=[0, 1])\n            discriminator = nn.DataParallel(discriminator, config.GPU)\n        l1_loss = nn.L1Loss()\n        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n\n        self.add_module('generator', generator)\n        self.add_module('discriminator', discriminator)\n\n        self.add_module('l1_loss', l1_loss)\n        self.add_module('adversarial_loss', adversarial_loss)\n\n        self.gen_optimizer = optim.Adam(\n            params=generator.parameters(),\n            lr=float(config.LR),\n            betas=(config.BETA1, config.BETA2)\n        )\n\n        self.dis_optimizer = optim.Adam(\n            params=discriminator.parameters(),\n            lr=float(config.LR) * float(config.D2G_LR),\n            betas=(config.BETA1, config.BETA2)\n        )\n\n    def process(self, images, edges, masks):\n        self.iteration += 1\n\n\n        # zero optimizers\n        self.gen_optimizer.zero_grad()\n        self.dis_optimizer.zero_grad()\n\n\n        # process outputs\n        outputs = self(images, edges, masks)\n        gen_loss = 0\n        dis_loss = 0\n\n\n        # discriminator loss\n        dis_input_real = torch.cat((images, edges), dim=1)\n        dis_input_fake = torch.cat((images, outputs.detach()), dim=1)\n        dis_real, dis_real_feat = self.discriminator(dis_input_real)        # in: (grayscale(1) + edge(1))\n        dis_fake, dis_fake_feat = self.discriminator(dis_input_fake)        # in: (grayscale(1) + edge(1))\n        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n        dis_loss += (dis_real_loss.clone() + dis_fake_loss.clone()) / 2\n\n\n        # generator adversarial loss\n        gen_input_fake = torch.cat((images, outputs), dim=1)\n        gen_fake, gen_fake_feat = self.discriminator(gen_input_fake)        # in: (grayscale(1) + edge(1))\n        gen_gan_loss = self.adversarial_loss(gen_fake, True, False)\n        gen_loss += gen_gan_loss.clone()\n\n\n        # generator feature matching loss\n        gen_fm_loss = 0\n        for i in range(len(dis_real_feat)):\n            gen_fm_loss += self.l1_loss(gen_fake_feat[i], dis_real_feat[i].detach())\n        gen_fm_loss = gen_fm_loss * self.config.FM_LOSS_WEIGHT\n        gen_loss += gen_fm_loss\n\n\n        # create logs\n        logs = [\n            (\"l_d1\", dis_loss.item()),\n            (\"l_g1\", gen_gan_loss.item()),\n            (\"l_fm\", gen_fm_loss.item()),\n        ]\n\n        return outputs, gen_loss, dis_loss, logs\n\n    def forward(self, images, edges, masks):\n        edges_masked = (edges * (1 - masks))\n        images_masked = (images * (1 - masks)) + masks\n        inputs = torch.cat((images_masked, edges_masked, masks), dim=1)\n        outputs = self.generator(inputs)                                    # in: [grayscale(1) + edge(1) + mask(1)]\n        return outputs\n\n    def backward(self, gen_loss=None, dis_loss=None):\n        if dis_loss is not None:\n            dis_loss.backward()\n        self.dis_optimizer.step()\n\n        if gen_loss is not None:\n            gen_loss = gen_loss.backward().clone()\n        self.gen_optimizer.step()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-23T16:16:24.104436Z","iopub.execute_input":"2023-03-23T16:16:24.104910Z","iopub.status.idle":"2023-03-23T16:16:24.882169Z","shell.execute_reply.started":"2023-03-23T16:16:24.104807Z","shell.execute_reply":"2023-03-23T16:16:24.881073Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass EdgeAccuracy(nn.Module):\n    \"\"\"\n    Measures the accuracy of the edge map\n    \"\"\"\n    def __init__(self, threshold=0.5):\n        super(EdgeAccuracy, self).__init__()\n        self.threshold = threshold\n\n    def __call__(self, inputs, outputs):\n        labels = (inputs > self.threshold)\n        outputs = (outputs > self.threshold)\n\n        relevant = torch.sum(labels.float())\n        selected = torch.sum(outputs.float())\n\n        if relevant == 0 and selected == 0:\n            return torch.tensor(1), torch.tensor(1)\n\n        true_positive = ((outputs == labels) * labels).float()\n        recall = torch.sum(true_positive) / (relevant + 1e-8)\n        precision = torch.sum(true_positive) / (selected + 1e-8)\n\n        return precision, recall\n\n\nclass PSNR(nn.Module):\n    def __init__(self, max_val):\n        super(PSNR, self).__init__()\n\n        base10 = torch.log(torch.tensor(10.0))\n        max_val = torch.tensor(max_val).float()\n\n        self.register_buffer('base10', base10)\n        self.register_buffer('max_val', 20 * torch.log(max_val) / base10)\n\n    def __call__(self, a, b):\n        mse = torch.mean((a.float() - b.float()) ** 2)\n\n        if mse == 0:\n            return torch.tensor(0)\n\n        return self.max_val - 10 * torch.log(mse) / self.base10","metadata":{"execution":{"iopub.status.busy":"2023-03-23T16:16:24.885328Z","iopub.execute_input":"2023-03-23T16:16:24.885797Z","iopub.status.idle":"2023-03-23T16:16:24.898084Z","shell.execute_reply.started":"2023-03-23T16:16:24.885747Z","shell.execute_reply":"2023-03-23T16:16:24.896740Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nimport tensorflow as tf\n# from .dataset import Dataset\n# from .models import EdgeModel, InpaintingModel\n# from .utils import Progbar, create_dir, stitch_images, imsave\n# from .metrics import PSNR, EdgeAccuracy\n\n\nclass EdgeConnect():\n    \n    def cuda(self, *args):\n        return (item.to(self.config.DEVICE) for item in args)\n    \n    def __init__(self, config):\n        self.config = config\n        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in config.GPU)\n        if torch.cuda.is_available():\n            config.DEVICE = torch.device(\"cuda\")\n            torch.backends.cudnn.benchmark = True   # cudnn auto-tuner\n        else:\n            config.DEVICE = torch.device(\"cpu\")\n        print(torch.cuda.is_available())\n        self.edge_model = EdgeModel(config).to(config.DEVICE)\n        self.edgeacc = EdgeAccuracy(config.EDGE_THRESHOLD).to(config.DEVICE)\n#         self.inpaint_model = InpaintingModel(config).to(config.DEVICE)\n        self.train_dataset = Dataset(256, '/kaggle/input/train-test-set/val_256', augment=True, training=True)\n        train_loader = DataLoader(\n            dataset=self.train_dataset,\n            batch_size=self.config.BATCH_SIZE,\n            num_workers=4,\n            drop_last=True,\n            shuffle=True\n        )\n        transform = T.ToPILImage()\n        for items in train_loader:\n\n            self.edge_model.train()\n            images, images_gray, edges, masks = self.cuda(*items)\n            outputs, gen_loss, dis_loss, logs = self.edge_model.process(images_gray, edges, masks)\n\n            # metrics\n            precision, recall = self.edgeacc(edges * masks, outputs * masks)\n            logs.append(('precision', precision.item()))\n            logs.append(('recall', recall.item()))\n\n            # backward\n            self.edge_model.backward(gen_loss, dis_loss)\n            iteration = self.edge_model.iteration\n            \n            if iteration >= max_iteration:\n                keep_training = False\n                break\n\n            logs = [\n                (\"epoch\", epoch),\n                (\"iter\", iteration),\n            ] + logs\n\n            progbar.add(len(images), values=logs if self.config.VERBOSE else [x for x in logs if not x[0].startswith('l_')])\n\n            # log model at checkpoints\n            if self.config.LOG_INTERVAL and iteration % self.config.LOG_INTERVAL == 0:\n                self.log(logs)\n\n            # sample model at checkpoints\n            if self.config.SAMPLE_INTERVAL and iteration % self.config.SAMPLE_INTERVAL == 0:\n                self.sample()\n\n            # evaluate model at checkpoints\n            if self.config.EVAL_INTERVAL and iteration % self.config.EVAL_INTERVAL == 0:\n                print('\\nstart eval...\\n')\n                self.eval()\n\n            # save model at checkpoints\n            if self.config.SAVE_INTERVAL and iteration % self.config.SAVE_INTERVAL == 0:\n                self.save()\n\n        print('\\nEnd training....')\n            \n            \n#             images = edges[0,...]\n#             images = images[0,...]\n#             print(tf.shape(images))\n#             arr_ = np.squeeze(images) # you can give axis attribute if you wanna squeeze in specific dimension\n#             plt.imshow(arr_, cmap=\"gray\")\n#             plt.show()\n            \nconfig = Config()            \nedgeConnect = EdgeConnect(config)","metadata":{"execution":{"iopub.status.busy":"2023-03-23T16:16:24.899961Z","iopub.execute_input":"2023-03-23T16:16:24.900460Z","iopub.status.idle":"2023-03-23T16:16:41.292623Z","shell.execute_reply.started":"2023-03-23T16:16:24.900398Z","shell.execute_reply":"2023-03-23T16:16:41.290873Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"False\n/kaggle\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:81: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:81: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:81: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:81: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py:199: UserWarning: Error detected in DivBackward0. Traceback of forward call that caused the error:\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n    cell_id=cell_id,\n  File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n    raw_cell, store_history, silent, shell_futures, cell_id\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n    return runner(coro)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_27/3325699928.py\", line 94, in <module>\n    edgeConnect = EdgeConnect(config)\n  File \"/tmp/ipykernel_27/3325699928.py\", line 44, in __init__\n    outputs, gen_loss, dis_loss, logs = self.edge_model.process(images_gray, edges, masks)\n  File \"/tmp/ipykernel_27/1056180354.py\", line 114, in process\n    gen_fake, gen_fake_feat = self.discriminator(gen_input_fake)        # in: (grayscale(1) + edge(1))\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_27/2970340681.py\", line 125, in forward\n    conv5 = self.conv5(conv4)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 204, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1197, in _call_impl\n    result = hook(self, input)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/utils/spectral_norm.py\", line 107, in __call__\n    setattr(module, self.name, self.compute_weight(module, do_power_iteration=module.training))\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/utils/spectral_norm.py\", line 94, in compute_weight\n    weight = weight / sigma\n  File \"/opt/conda/lib/python3.7/site-packages/torch/fx/traceback.py\", line 57, in format_stack\n    return traceback.format_stack()\n (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)\n  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3325699928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0medgeConnect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEdgeConnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/3325699928.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/1056180354.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gen_loss, dis_loss)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgen_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[1;32m    487\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 488\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         )\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n","\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 512, 4, 4]] is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"],"ename":"RuntimeError","evalue":"one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 512, 4, 4]] is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!","output_type":"error"}]}]}