{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"class Config(dict):\n    def __init__(self, config_path):\n        self._dict['PATH'] = os.path.dirname('/kaggle/working/weights/')\n    def __getattr__(self, name):\n        if DEFAULT_CONFIG.get(name) is not None:\n            return DEFAULT_CONFIG[name]\n        return None\n\n\nDEFAULT_CONFIG = {\n    'MODE': 1,                      # 1: train, 2: test, 3: eval\n    'MODEL': 1,                     # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n    'MASK': 3,                      # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n    'EDGE': 1,                      # 1: canny, 2: external\n    'NMS': 1,                       # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n    'SEED': 10,                     # random seed\n    'GPU': [0],                     # list of gpu ids\n    'DEBUG': 0,                     # turns on debugging mode\n    'VERBOSE': 0,                   # turns on verbose mode in the output console\n\n    'LR': 0.0001,                   # learning rate\n    'D2G_LR': 0.1,                  # discriminator/generator learning rate ratio\n    'BETA1': 0.0,                   # adam optimizer beta1\n    'BETA2': 0.9,                   # adam optimizer beta2\n    'BATCH_SIZE': 8,                # input batch size for training\n    'INPUT_SIZE': 256,              # input image size for training 0 for original size\n    'SIGMA': 2,                     # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n    'MAX_ITERS': 2e6,               # maximum number of iterations to train the model\n\n    'EDGE_THRESHOLD': 0.5,          # edge detection threshold\n    'L1_LOSS_WEIGHT': 1,            # l1 loss weight\n    'FM_LOSS_WEIGHT': 10,           # feature-matching loss weight\n    'STYLE_LOSS_WEIGHT': 1,         # style loss weight\n    'CONTENT_LOSS_WEIGHT': 1,       # perceptual loss weight\n    'INPAINT_ADV_LOSS_WEIGHT': 0.01,# adversarial loss weight\n\n    'GAN_LOSS': 'nsgan',            # nsgan | lsgan | hinge\n    'GAN_POOL_SIZE': 0,             # fake images pool size\n\n    'SAVE_INTERVAL': 1000,          # how many iterations to wait before saving model (0: never)\n    'SAMPLE_INTERVAL': 1000,        # how many iterations to wait before sampling (0: never)\n    'SAMPLE_SIZE': 12,              # number of images to sample\n    'EVAL_INTERVAL': 0,             # how many iterations to wait before model evaluation (0: never)\n    'LOG_INTERVAL': 10,             # how many iterations to wait before logging training status (0: never)\n}","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:12:33.992316Z","iopub.execute_input":"2023-03-22T18:12:33.992973Z","iopub.status.idle":"2023-03-22T18:12:34.021435Z","shell.execute_reply.started":"2023-03-22T18:12:33.992905Z","shell.execute_reply":"2023-03-22T18:12:34.018803Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport scipy\nimport torch\nimport random\nimport numpy as np\nimport torchvision.transforms.functional as F\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport skimage\nimport matplotlib.pyplot as plt\nfrom skimage.feature import canny\nfrom skimage.color import rgb2gray, gray2rgb\n\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, input_size, filepath, augment=True, training=True, maskType=1):\n        super(Dataset, self).__init__()\n        self.augment = augment\n        self.training = training\n        self.data = self.load_flist(filepath)\n        self.input_size = input_size\n#             self.edge_data = self.load_flist(edge_flist)\n#             self.mask_data = self.load_flist(mask_flist)\n        self.sigma = 1.5\n        self.nms = 1\n        self.mask = maskType\n\n        # in test mode, there's a one-to-one relationship between mask and image\n        # masks are loaded non random\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        try:\n            item = self.load_item(index)\n        except:\n            print('loading error: ' + self.data[index])\n            item = self.load_item(0)\n\n        return item\n\n    def load_flist(self, flist):\n        imagesPath = []\n        for filename in os.listdir(flist):\n            imagesPath.append(os.path.join(flist,filename))\n        return imagesPath\n\n    def load_item(self, index):\n        size = self.input_size\n        img =  cv2.imread(self.data[index])\n        if len(img.shape) < 3:\n            img = gray2rgb(img)\n        if size != 0:\n            img = self.resize(img, size, size)\n        img_gray = rgb2gray(img)\n        mask = self.load_mask(img, index)\n        edge = self.load_edge(img_gray, index, mask)\n        if self.augment and np.random.binomial(1, 0.5) > 0:\n            img = img[:, ::-1, ...]\n            img_gray = img_gray[:, ::-1, ...]\n            edge = edge[:, ::-1, ...]\n            mask = mask[:, ::-1, ...]\n\n        return self.to_tensor(img), self.to_tensor(img_gray), self.to_tensor(edge), self.to_tensor(mask)\n    \n    def load_edge(self, img, index, mask):\n        sigma = self.sigma\n        mask = None if self.training else (1 - mask / 255).astype(np.bool)\n\n        # canny\n        # no edge\n        if sigma == -1:\n            return np.zeros(img.shape).astype(np.float)\n\n        # random sigma\n        if sigma == 0:\n            sigma = random.randint(1, 4)\n\n        return canny(img, sigma=sigma, mask=mask).astype(np.float)\n    \n    def load_mask(self, img, index):\n        imgh, imgw = img.shape[0:2]\n        mask_type = self.mask\n\n        # external + random block\n        if mask_type == 4:\n            mask_type = 1 if np.random.binomial(1, 0.5) == 1 else 3\n\n        # external + random block + half\n        elif mask_type == 5:\n            mask_type = np.random.randint(1, 4)\n\n        # random block\n        if mask_type == 1:\n            return self.create_mask(imgw, imgh, imgw // 4, imgh // 4)\n\n        # half\n        if mask_type == 2:\n            # randomly choose right or left\n            return self.create_mask(imgw, imgh, imgw // 2, imgh, 0 if random.random() < 0.5 else imgw // 2, 0)\n\n        # external\n        if mask_type == 3:\n            mask_index = random.randint(0, len(self.mask_data) - 1)\n            mask = imread(self.mask_data[mask_index])\n            mask = self.resize(mask, imgh, imgw)\n            mask = (mask > 0).astype(np.uint8) * 255       # threshold due to interpolation\n            return mask\n\n        # test mode: load mask non random\n        if mask_type == 6:\n            mask = imread(self.mask_data[index])\n            mask = self.resize(mask, imgh, imgw, centerCrop=False)\n            mask = rgb2gray(mask)\n            mask = (mask > 0).astype(np.uint8) * 255\n            return mask\n        \n    def resize(self, img, height, width, centerCrop=True):\n        imgh, imgw = img.shape[0:2]\n        if centerCrop and imgh != imgw:\n            # center crop\n            side = np.minimum(imgh, imgw)\n            j = (imgh - side) // 2\n            i = (imgw - side) // 2\n            img = img[j:j + side, i:i + side, ...]\n\n        img = cv2.resize(img, (height, width))\n        return img  \n    \n    def to_tensor(self, img):\n        img = Image.fromarray(img)\n#         plt.imshow(img)    \n#         plt.show()\n        img_t = F.to_tensor(img).float()\n        return img_t\n    \n    def create_mask(self, width, height, mask_width, mask_height, x=None, y=None):\n        mask = np.zeros((height, width))\n        mask_x = x if x is not None else random.randint(0, width - mask_width)\n        mask_y = y if y is not None else random.randint(0, height - mask_height)\n        mask[mask_y:mask_y + mask_height, mask_x:mask_x + mask_width] = 1\n        return mask","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-22T18:12:34.061787Z","iopub.execute_input":"2023-03-22T18:12:34.062394Z","iopub.status.idle":"2023-03-22T18:12:34.189050Z","shell.execute_reply.started":"2023-03-22T18:12:34.062341Z","shell.execute_reply":"2023-03-22T18:12:34.186783Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nclass BaseNetwork(nn.Module):\n    def __init__(self):\n        super(BaseNetwork, self).__init__()\n\n    def init_weights(self, init_type='normal', gain=0.02):\n        '''\n        initialize network's weights\n        init_type: normal | xavier | kaiming | orthogonal\n        https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/9451e70673400885567d08a9e97ade2524c700d0/models/networks.py#L39\n        '''\n\n        def init_func(m):\n            classname = m.__class__.__name__\n            if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n                if init_type == 'normal':\n                    nn.init.normal_(m.weight.data, 0.0, gain)\n                elif init_type == 'xavier':\n                    nn.init.xavier_normal_(m.weight.data, gain=gain)\n                elif init_type == 'kaiming':\n                    nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n                elif init_type == 'orthogonal':\n                    nn.init.orthogonal_(m.weight.data, gain=gain)\n\n                if hasattr(m, 'bias') and m.bias is not None:\n                    nn.init.constant_(m.bias.data, 0.0)\n\n            elif classname.find('BatchNorm2d') != -1:\n                nn.init.normal_(m.weight.data, 1.0, gain)\n                nn.init.constant_(m.bias.data, 0.0)\n\n        self.apply(init_func)\n\n\nclass EdgeGenerator(BaseNetwork):\n    def __init__(self, residual_blocks=8, use_spectral_norm=True, init_weights=True):\n        super(EdgeGenerator, self).__init__()\n\n        self.encoder = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            spectral_norm(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, padding=0), use_spectral_norm),\n            nn.InstanceNorm2d(64, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(128, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(256, track_running_stats=False),\n            nn.ReLU(True)\n        )\n\n        blocks = []\n        for _ in range(residual_blocks):\n            block = ResnetBlock(256, 2, use_spectral_norm=use_spectral_norm)\n            blocks.append(block)\n\n        self.middle = nn.Sequential(*blocks)\n\n        self.decoder = nn.Sequential(\n            spectral_norm(nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(128, track_running_stats=False),\n            nn.ReLU(True),\n\n            spectral_norm(nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1), use_spectral_norm),\n            nn.InstanceNorm2d(64, track_running_stats=False),\n            nn.ReLU(True),\n\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(in_channels=64, out_channels=1, kernel_size=7, padding=0),\n        )\n\n        if init_weights:\n            self.init_weights()\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.middle(x)\n        x = self.decoder(x)\n        x = torch.sigmoid(x)\n        return x\n\n\nclass Discriminator(BaseNetwork):\n    def __init__(self, in_channels, use_sigmoid=True, use_spectral_norm=True, init_weights=True):\n        super(Discriminator, self).__init__()\n        self.use_sigmoid = use_sigmoid\n\n        self.conv1 = self.features = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=in_channels, out_channels=64, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv2 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv3 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv4 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n\n        self.conv5 = nn.Sequential(\n            spectral_norm(nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1, bias=not use_spectral_norm), use_spectral_norm),\n        )\n\n        if init_weights:\n            self.init_weights()\n\n    def forward(self, x):\n        conv1 = self.conv1(x)\n        conv2 = self.conv2(conv1)\n        conv3 = self.conv3(conv2)\n        conv4 = self.conv4(conv3)\n        conv5 = self.conv5(conv4)\n\n        outputs = conv5\n        if self.use_sigmoid:\n            outputs = torch.sigmoid(conv5)\n\n        return outputs, [conv1, conv2, conv3, conv4, conv5]\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, dilation=1, use_spectral_norm=False):\n        super(ResnetBlock, self).__init__()\n        self.conv_block = nn.Sequential(\n            nn.ReflectionPad2d(dilation),\n            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=dilation, bias=not use_spectral_norm), use_spectral_norm),\n            nn.InstanceNorm2d(dim, track_running_stats=False),\n            nn.ReLU(True),\n\n            nn.ReflectionPad2d(1),\n            spectral_norm(nn.Conv2d(in_channels=dim, out_channels=dim, kernel_size=3, padding=0, dilation=1, bias=not use_spectral_norm), use_spectral_norm),\n            nn.InstanceNorm2d(dim, track_running_stats=False),\n        )\n\n    def forward(self, x):\n        out = x + self.conv_block(x)\n\n        # Remove ReLU at the end of the residual block\n        # http://torch.ch/blog/2016/02/04/resnets.html\n\n        return out\n\n\ndef spectral_norm(module, mode=True):\n    if mode:\n        return nn.utils.spectral_norm(module)\n\n    return module","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:17:58.933885Z","iopub.execute_input":"2023-03-22T18:17:58.934410Z","iopub.status.idle":"2023-03-22T18:17:58.971132Z","shell.execute_reply.started":"2023-03-22T18:17:58.934363Z","shell.execute_reply":"2023-03-22T18:17:58.969685Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n\nclass AdversarialLoss(nn.Module):\n    r\"\"\"\n    Adversarial loss\n    https://arxiv.org/abs/1711.10337\n    \"\"\"\n\n    def __init__(self, type='nsgan', target_real_label=1.0, target_fake_label=0.0):\n        r\"\"\"\n        type = nsgan | lsgan | hinge\n        \"\"\"\n        super(AdversarialLoss, self).__init__()\n\n        self.type = type\n        self.register_buffer('real_label', torch.tensor(target_real_label))\n        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n\n        if type == 'nsgan':\n            self.criterion = nn.BCELoss()\n\n        elif type == 'lsgan':\n            self.criterion = nn.MSELoss()\n\n        elif type == 'hinge':\n            self.criterion = nn.ReLU()\n\n    def __call__(self, outputs, is_real, is_disc=None):\n        if self.type == 'hinge':\n            if is_disc:\n                if is_real:\n                    outputs = -outputs\n                return self.criterion(1 + outputs).mean()\n            else:\n                return (-outputs).mean()\n\n        else:\n            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n            loss = self.criterion(outputs, labels)\n            return loss\n\n\nclass StyleLoss(nn.Module):\n    r\"\"\"\n    Perceptual loss, VGG-based\n    https://arxiv.org/abs/1603.08155\n    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n    \"\"\"\n\n    def __init__(self):\n        super(StyleLoss, self).__init__()\n        self.add_module('vgg', VGG19())\n        self.criterion = torch.nn.L1Loss()\n\n    def compute_gram(self, x):\n        b, ch, h, w = x.size()\n        f = x.view(b, ch, w * h)\n        f_T = f.transpose(1, 2)\n        G = f.bmm(f_T) / (h * w * ch)\n\n        return G\n\n    def __call__(self, x, y):\n        # Compute features\n        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n\n        # Compute loss\n        style_loss = 0.0\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu2_2']), self.compute_gram(y_vgg['relu2_2']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu3_4']), self.compute_gram(y_vgg['relu3_4']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu4_4']), self.compute_gram(y_vgg['relu4_4']))\n        style_loss += self.criterion(self.compute_gram(x_vgg['relu5_2']), self.compute_gram(y_vgg['relu5_2']))\n\n        return style_loss\n\n\n\nclass PerceptualLoss(nn.Module):\n    r\"\"\"\n    Perceptual loss, VGG-based\n    https://arxiv.org/abs/1603.08155\n    https://github.com/dxyang/StyleTransfer/blob/master/utils.py\n    \"\"\"\n\n    def __init__(self, weights=[1.0, 1.0, 1.0, 1.0, 1.0]):\n        super(PerceptualLoss, self).__init__()\n        self.add_module('vgg', VGG19())\n        self.criterion = torch.nn.L1Loss()\n        self.weights = weights\n\n    def __call__(self, x, y):\n        # Compute features\n        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n\n        content_loss = 0.0\n        content_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\n        content_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\n        content_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\n        content_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\n        content_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n\n\n        return content_loss\n\n\n\nclass VGG19(torch.nn.Module):\n    def __init__(self):\n        super(VGG19, self).__init__()\n        features = models.vgg19(pretrained=True).features\n        self.relu1_1 = torch.nn.Sequential()\n        self.relu1_2 = torch.nn.Sequential()\n\n        self.relu2_1 = torch.nn.Sequential()\n        self.relu2_2 = torch.nn.Sequential()\n\n        self.relu3_1 = torch.nn.Sequential()\n        self.relu3_2 = torch.nn.Sequential()\n        self.relu3_3 = torch.nn.Sequential()\n        self.relu3_4 = torch.nn.Sequential()\n\n        self.relu4_1 = torch.nn.Sequential()\n        self.relu4_2 = torch.nn.Sequential()\n        self.relu4_3 = torch.nn.Sequential()\n        self.relu4_4 = torch.nn.Sequential()\n\n        self.relu5_1 = torch.nn.Sequential()\n        self.relu5_2 = torch.nn.Sequential()\n        self.relu5_3 = torch.nn.Sequential()\n        self.relu5_4 = torch.nn.Sequential()\n\n        for x in range(2):\n            self.relu1_1.add_module(str(x), features[x])\n\n        for x in range(2, 4):\n            self.relu1_2.add_module(str(x), features[x])\n\n        for x in range(4, 7):\n            self.relu2_1.add_module(str(x), features[x])\n\n        for x in range(7, 9):\n            self.relu2_2.add_module(str(x), features[x])\n\n        for x in range(9, 12):\n            self.relu3_1.add_module(str(x), features[x])\n\n        for x in range(12, 14):\n            self.relu3_2.add_module(str(x), features[x])\n\n        for x in range(14, 16):\n            self.relu3_3.add_module(str(x), features[x])\n\n        for x in range(16, 18):\n            self.relu3_4.add_module(str(x), features[x])\n\n        for x in range(18, 21):\n            self.relu4_1.add_module(str(x), features[x])\n\n        for x in range(21, 23):\n            self.relu4_2.add_module(str(x), features[x])\n\n        for x in range(23, 25):\n            self.relu4_3.add_module(str(x), features[x])\n\n        for x in range(25, 27):\n            self.relu4_4.add_module(str(x), features[x])\n\n        for x in range(27, 30):\n            self.relu5_1.add_module(str(x), features[x])\n\n        for x in range(30, 32):\n            self.relu5_2.add_module(str(x), features[x])\n\n        for x in range(32, 34):\n            self.relu5_3.add_module(str(x), features[x])\n\n        for x in range(34, 36):\n            self.relu5_4.add_module(str(x), features[x])\n\n        # don't need the gradients, just want the features\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        relu1_1 = self.relu1_1(x)\n        relu1_2 = self.relu1_2(relu1_1)\n\n        relu2_1 = self.relu2_1(relu1_2)\n        relu2_2 = self.relu2_2(relu2_1)\n\n        relu3_1 = self.relu3_1(relu2_2)\n        relu3_2 = self.relu3_2(relu3_1)\n        relu3_3 = self.relu3_3(relu3_2)\n        relu3_4 = self.relu3_4(relu3_3)\n\n        relu4_1 = self.relu4_1(relu3_4)\n        relu4_2 = self.relu4_2(relu4_1)\n        relu4_3 = self.relu4_3(relu4_2)\n        relu4_4 = self.relu4_4(relu4_3)\n\n        relu5_1 = self.relu5_1(relu4_4)\n        relu5_2 = self.relu5_2(relu5_1)\n        relu5_3 = self.relu5_3(relu5_2)\n        relu5_4 = self.relu5_4(relu5_3)\n\n        out = {\n            'relu1_1': relu1_1,\n            'relu1_2': relu1_2,\n\n            'relu2_1': relu2_1,\n            'relu2_2': relu2_2,\n\n            'relu3_1': relu3_1,\n            'relu3_2': relu3_2,\n            'relu3_3': relu3_3,\n            'relu3_4': relu3_4,\n\n            'relu4_1': relu4_1,\n            'relu4_2': relu4_2,\n            'relu4_3': relu4_3,\n            'relu4_4': relu4_4,\n\n            'relu5_1': relu5_1,\n            'relu5_2': relu5_2,\n            'relu5_3': relu5_3,\n            'relu5_4': relu5_4,\n        }\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:18:03.974164Z","iopub.execute_input":"2023-03-22T18:18:03.974654Z","iopub.status.idle":"2023-03-22T18:18:04.018545Z","shell.execute_reply.started":"2023-03-22T18:18:03.974616Z","shell.execute_reply":"2023-03-22T18:18:04.016865Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\nclass BaseModel(nn.Module):\n    def __init__(self, name, config):\n        super(BaseModel, self).__init__()\n\n        self.name = name\n        self.config = config\n        self.iteration = 0\n\n        self.gen_weights_path = os.path.join(config.PATH, name + '_gen.pth')\n        self.dis_weights_path = os.path.join(config.PATH, name + '_dis.pth')\n\n    def load(self):\n        if os.path.exists(self.gen_weights_path):\n            print('Loading %s generator...' % self.name)\n\n            if torch.cuda.is_available():\n                data = torch.load(self.gen_weights_path)\n            else:\n                data = torch.load(self.gen_weights_path, map_location=lambda storage, loc: storage)\n\n            self.generator.load_state_dict(data['generator'])\n            self.iteration = data['iteration']\n\n        # load discriminator only when training\n        if self.config.MODE == 1 and os.path.exists(self.dis_weights_path):\n            print('Loading %s discriminator...' % self.name)\n\n            if torch.cuda.is_available():\n                data = torch.load(self.dis_weights_path)\n            else:\n                data = torch.load(self.dis_weights_path, map_location=lambda storage, loc: storage)\n\n            self.discriminator.load_state_dict(data['discriminator'])\n\n    def save(self):\n        print('\\nsaving %s...\\n' % self.name)\n        torch.save({\n            'iteration': self.iteration,\n            'generator': self.generator.state_dict()\n        }, self.gen_weights_path)\n\n        torch.save({\n            'discriminator': self.discriminator.state_dict()\n        }, self.dis_weights_path)\n\n\nclass EdgeModel(BaseModel):\n    def __init__(self, config):\n        super(EdgeModel, self).__init__('EdgeModel', config)\n\n        # generator input: [grayscale(1) + edge(1) + mask(1)]\n        # discriminator input: (grayscale(1) + edge(1))\n        generator = EdgeGenerator(use_spectral_norm=True)\n        discriminator = Discriminator(in_channels=2, use_sigmoid=config.GAN_LOSS != 'hinge')\n        if len(config.GPU) > 1:\n            generator = nn.DataParallel(generator, config.GPU)\n            discriminator = nn.DataParallel(discriminator, config.GPU)\n        l1_loss = nn.L1Loss()\n        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n\n        self.add_module('generator', generator)\n        self.add_module('discriminator', discriminator)\n\n        self.add_module('l1_loss', l1_loss)\n        self.add_module('adversarial_loss', adversarial_loss)\n\n        self.gen_optimizer = optim.Adam(\n            params=generator.parameters(),\n            lr=float(config.LR),\n            betas=(config.BETA1, config.BETA2)\n        )\n\n        self.dis_optimizer = optim.Adam(\n            params=discriminator.parameters(),\n            lr=float(config.LR) * float(config.D2G_LR),\n            betas=(config.BETA1, config.BETA2)\n        )\n\n    def process(self, images, edges, masks):\n        self.iteration += 1\n\n\n        # zero optimizers\n        self.gen_optimizer.zero_grad()\n        self.dis_optimizer.zero_grad()\n\n\n        # process outputs\n        outputs = self(images, edges, masks)\n        gen_loss = 0\n        dis_loss = 0\n\n\n        # discriminator loss\n        dis_input_real = torch.cat((images, edges), dim=1)\n        dis_input_fake = torch.cat((images, outputs.detach()), dim=1)\n        dis_real, dis_real_feat = self.discriminator(dis_input_real)        # in: (grayscale(1) + edge(1))\n        dis_fake, dis_fake_feat = self.discriminator(dis_input_fake)        # in: (grayscale(1) + edge(1))\n        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n\n\n        # generator adversarial loss\n        gen_input_fake = torch.cat((images, outputs), dim=1)\n        gen_fake, gen_fake_feat = self.discriminator(gen_input_fake)        # in: (grayscale(1) + edge(1))\n        gen_gan_loss = self.adversarial_loss(gen_fake, True, False)\n        gen_loss += gen_gan_loss\n\n\n        # generator feature matching loss\n        gen_fm_loss = 0\n        for i in range(len(dis_real_feat)):\n            gen_fm_loss += self.l1_loss(gen_fake_feat[i], dis_real_feat[i].detach())\n        gen_fm_loss = gen_fm_loss * self.config.FM_LOSS_WEIGHT\n        gen_loss += gen_fm_loss\n\n\n        # create logs\n        logs = [\n            (\"l_d1\", dis_loss.item()),\n            (\"l_g1\", gen_gan_loss.item()),\n            (\"l_fm\", gen_fm_loss.item()),\n        ]\n\n        return outputs, gen_loss, dis_loss, logs\n\n    def forward(self, images, edges, masks):\n        edges_masked = (edges * (1 - masks))\n        images_masked = (images * (1 - masks)) + masks\n        inputs = torch.cat((images_masked, edges_masked, masks), dim=1)\n        outputs = self.generator(inputs)                                    # in: [grayscale(1) + edge(1) + mask(1)]\n        return outputs\n\n    def backward(self, gen_loss=None, dis_loss=None):\n        if dis_loss is not None:\n            dis_loss.backward()\n        self.dis_optimizer.step()\n\n        if gen_loss is not None:\n            gen_loss.backward()\n        self.gen_optimizer.step()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:18:16.771499Z","iopub.execute_input":"2023-03-22T18:18:16.771959Z","iopub.status.idle":"2023-03-22T18:18:16.798597Z","shell.execute_reply.started":"2023-03-22T18:18:16.771920Z","shell.execute_reply":"2023-03-22T18:18:16.797478Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as T\nimport tensorflow as tf\n# from .dataset import Dataset\n# from .models import EdgeModel, InpaintingModel\n# from .utils import Progbar, create_dir, stitch_images, imsave\n# from .metrics import PSNR, EdgeAccuracy\n\n\nclass EdgeConnect():\n    def __init__(self, config):\n        self.config = config\n        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(str(e) for e in config.GPU)\n        if torch.cuda.is_available():\n            config.DEVICE = torch.device(\"cuda\")\n            torch.backends.cudnn.benchmark = True   # cudnn auto-tuner\n        else:\n            config.DEVICE = torch.device(\"cpu\")\n        self.edge_model = EdgeModel(config).to(config.DEVICE)\n#         self.inpaint_model = InpaintingModel(config).to(config.DEVICE)\n        self.train_dataset = Dataset(256, '/kaggle/input/train-test-set/val_256', augment=True, training=True)\n        train_loader = DataLoader(\n            dataset=self.train_dataset,\n            batch_size=self.config.BATCH_SIZE,\n            num_workers=4,\n            drop_last=True,\n            shuffle=True\n        )\n        transform = T.ToPILImage()\n        for items in train_loader:\n            images, images_gray, edges, masks = items\n            images = edges[0,...]\n            images = images[0,...]\n            print(tf.shape(images))\n            arr_ = np.squeeze(images) # you can give axis attribute if you wanna squeeze in specific dimension\n            plt.imshow(arr_, cmap=\"gray\")\n            plt.show()\n            \nconfig = Config()            \nedgeConnect = EdgeConnect(config)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:21:54.912693Z","iopub.execute_input":"2023-03-22T18:21:54.913182Z","iopub.status.idle":"2023-03-22T18:21:55.014853Z","shell.execute_reply.started":"2023-03-22T18:21:54.913138Z","shell.execute_reply":"2023-03-22T18:21:55.012926Z"},"trusted":true},"execution_count":203,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1380300626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0medgeConnect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEdgeConnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/1380300626.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEdgeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m#         self.inpaint_model = InpaintingModel(config).to(config.DEVICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/kaggle/input/train-test-set/val_256'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/4000835541.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEdgeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEdgeModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EdgeModel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# generator input: [grayscale(1) + edge(1) + mask(1)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/4000835541.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, config)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_weights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_gen.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdis_weights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_dis.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"],"ename":"TypeError","evalue":"expected str, bytes or os.PathLike object, not NoneType","output_type":"error"}]},{"cell_type":"code","source":"import tensorflow as tf\n\ntf.compat.v1.disable_eager_execution()\nsess = tf.compat.v1.Session()\ninit = tf.compat.v1.global_variables_initializer()\nsess.run(init)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T18:12:39.236176Z","iopub.status.idle":"2023-03-22T18:12:39.247080Z","shell.execute_reply.started":"2023-03-22T18:12:39.246506Z","shell.execute_reply":"2023-03-22T18:12:39.246575Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}